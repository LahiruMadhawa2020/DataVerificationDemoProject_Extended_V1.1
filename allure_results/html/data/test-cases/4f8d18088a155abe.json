{
  "uid" : "4f8d18088a155abe",
  "name" : "test_source_target_comparison",
  "fullName" : "test_tc1_execute_testcsv#test_source_target_comparison",
  "historyId" : "bdb262de352c94a4babec0c2a8777a17",
  "time" : {
    "start" : 1606723528019,
    "stop" : 1606723528079,
    "duration" : 60
  },
  "status" : "broken",
  "statusMessage" : "FileExistsError: [Errno 17] File exists: 'reports/reports_comparison/report11a.html'",
  "statusTrace" : "csv_source_s1 =     id   name               address        email  age gender\n0  1.0   AAAA  23, asdassdas,adaads  abc@abc.com   34    ... 6.0  AAAFA  28, asdassdas,adaads  abh@abc.com   37      M\n6  7.0   AAAG  29, asdassdas,adaads  abi@abc.com   80      A\ncsv_source_s2 =     id   name               address        email  age gender\n0  1.0   AAAA  23, asdassdas,adaads  abc@abc.com   34    ... 5.0   AAAG  29, asdassdas,adaads  abi@abc.com   80      A\n5  6.0  AAAFA  28, asdassdas,adaads  abh@abc.com   37      M\n\n    @allure.feature('test_module_03')\n    @allure.story('test_story_01')\n    @allure.severity('critical')\n    @pytest.mark.run(order=7)\n    def test_source_target_comparison(csv_source_s1, csv_source_s2):\n>       comparison = Validation().compare_table1_values_with_table2_values(csv_source_s1, csv_source_s2)\n\ntest_tc1_execute_testcsv.py:172: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <validationrules.validation.Validation object at 0x00000222386410A0>\nvalue1 =     id   name               address        email  age gender\n0  1.0   AAAA  23, asdassdas,adaads  abc@abc.com   34    ... 6.0  AAAFA  28, asdassdas,adaads  abh@abc.com   37      M\n6  7.0   AAAG  29, asdassdas,adaads  abi@abc.com   80      A\nvalue2 =     id   name               address        email  age gender\n0  1.0   AAAA  23, asdassdas,adaads  abc@abc.com   34    ... 5.0   AAAG  29, asdassdas,adaads  abi@abc.com   80      A\n5  6.0  AAAFA  28, asdassdas,adaads  abh@abc.com   37      M\n\n    def compare_table1_values_with_table2_values(self, value1, value2):\n        df1 = value1\n        df2 = value2\n        compare = datacompy.Compare(\n            df1,\n            df2,\n            # You can also specify a list of columns\n            # join_columns='ID',\n            # if column names are not matching\n            on_index=True,\n            # Optional, defaults to 0\n            # abs_tol=0,\n            # Optional, defaults to 0\n            # rel_tol=0,\n            # Optional, defaults to 'df1'\n            df1_name='Source',\n            # Optional, defaults to 'df2'\n            df2_name='Target'\n        )\n        # ignore_extra_columns is False\n        compare.matches(ignore_extra_columns=False)\n        # is there any sort of a mismatch between row values\n        rows_match = compare.all_rows_overlap()\n        # is there any sort of a mismatch between column values\n        columns_match = compare.all_columns_match()\n        # number of columns and rows are matching\n        overlap_rows = compare.all_rows_overlap()\n        # This method prints out a human-readable report summarizing and sampling differences\n        report = compare.report()\n>       f = open(\"reports/reports_comparison/report11a.html\", \"x\")\nE       FileExistsError: [Errno 17] File exists: 'reports/reports_comparison/report11a.html'\n\nvalidationrules\\validation.py:321: FileExistsError",
  "flaky" : false,
  "newFailed" : false,
  "beforeStages" : [ {
    "name" : "csv_source_s1",
    "time" : {
      "start" : 1606723528012,
      "stop" : 1606723528015,
      "duration" : 3
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false,
    "stepsCount" : 0
  }, {
    "name" : "csv_source_s2",
    "time" : {
      "start" : 1606723528015,
      "stop" : 1606723528018,
      "duration" : 3
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false,
    "stepsCount" : 0
  } ],
  "afterStages" : [ ],
  "labels" : [ {
    "name" : "severity",
    "value" : "critical"
  }, {
    "name" : "story",
    "value" : "test_story_01"
  }, {
    "name" : "feature",
    "value" : "test_module_03"
  }, {
    "name" : "tag",
    "value" : "run(order=7)"
  }, {
    "name" : "suite",
    "value" : "test_tc1_execute_testcsv"
  }, {
    "name" : "host",
    "value" : "ZSRIL-1X760Z2"
  }, {
    "name" : "thread",
    "value" : "19992-MainThread"
  }, {
    "name" : "framework",
    "value" : "pytest"
  }, {
    "name" : "language",
    "value" : "cpython3"
  }, {
    "name" : "package",
    "value" : "test_tc1_execute_testcsv"
  }, {
    "name" : "resultFormat",
    "value" : "allure2"
  } ],
  "parameters" : [ ],
  "links" : [ ],
  "hidden" : true,
  "retry" : true,
  "extra" : {
    "categories" : [ ],
    "tags" : [ "run(order=7)" ]
  },
  "source" : "4f8d18088a155abe.json",
  "parameterValues" : [ ]
}